{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "import cPickle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import load_data\n",
    "from model import StrSumModel\n",
    "from run import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(tf.flags.FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cli.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string('visible_gpu', '4', 'visible_gpu')\n",
    "\n",
    "dataname = 'sports_fined.pkl'\n",
    "flags.DEFINE_string('datapath', os.path.join('data', dataname), 'datapath')\n",
    "modeldir = 'model_rougel_fined'\n",
    "modelname = 'sports'\n",
    "flags.DEFINE_string('modeldir', modeldir, 'modeldir')\n",
    "flags.DEFINE_string('modelpath', os.path.join(modeldir, 'sports'), 'modeldir')\n",
    "\n",
    "flags.DEFINE_bool('discourserank', True, 'discourserank')\n",
    "flags.DEFINE_float('damp', 0.9, 'damping factor of discourserank')\n",
    "\n",
    "flags.DEFINE_integer('epochs', 1000, 'epochs')\n",
    "flags.DEFINE_integer('log_period', 500, 'log_period')\n",
    "\n",
    "flags.DEFINE_string('opt', 'Adagrad', 'optimizer')\n",
    "flags.DEFINE_float('lr', 0.1, 'lr')\n",
    "flags.DEFINE_float('norm', 1e-4, 'norm')\n",
    "flags.DEFINE_float('grad_clip', 10.0, 'grad_clip')\n",
    "flags.DEFINE_float('keep_prob', 0.95, 'keep_prob')\n",
    "flags.DEFINE_float('length_penalty_weight', 0.0, 'length_penalty_weight')\n",
    "\n",
    "flags.DEFINE_integer('dim_hidden', 256, 'dim_output')\n",
    "flags.DEFINE_integer('dim_str', 128, 'dim_output')\n",
    "flags.DEFINE_integer('dim_sent', 384, 'dim_sent')\n",
    "\n",
    "flags.DEFINE_integer('beam_width', 10, 'beam_width')\n",
    "flags.DEFINE_integer('batch_size', 8, 'batch_size')\n",
    "\n",
    "flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = flags.FLAGS\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = config.visible_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import rouge_n, rouge_l_sentence_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = '<pad>' # This has a vocab id, which is used to pad the encoder input, decoder input and target sequence\n",
    "UNK = '<unk>' # This has a vocab id, which is used to represent out-of-vocabulary words\n",
    "BOS = '<p>' # This has a vocab id, which is used at the beginning of every decoder input sequence\n",
    "EOS = '</p>' # This has a vocab id, which is used at the end of untruncated target sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples,  train_batches, dev_batches, test_batches, embedding_matrix, vocab, word_to_id = load_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.n_embed, config.d_embed = embedding_matrix.shape\n",
    "flags.DEFINE_integer('n_embed', embedding_matrix.shape[0], 'n_embed')\n",
    "flags.DEFINE_integer('d_embed', embedding_matrix.shape[1], 'd_embed')\n",
    "# config.maximum_iterations = max([max([d._max_sent_len(None) for d in batch]) for ct, batch in dev_batches])\n",
    "maximum_iterations = max([max([d._max_sent_len(None) for d in batch]) for ct, batch in dev_batches])\n",
    "flags.DEFINE_integer('maximum_iterations', maximum_iterations, 'maximum_iterations')\n",
    "flags.DEFINE_integer('PAD_IDX', word_to_id[PAD], 'PAD_IDX')\n",
    "flags.DEFINE_integer('UNK_IDX', word_to_id[UNK], 'UNK_IDX')\n",
    "flags.DEFINE_integer('BOS_IDX', word_to_id[BOS], 'BOS_IDX')\n",
    "flags.DEFINE_integer('EOS_IDX', word_to_id[EOS], 'EOS_IDX')\n",
    "# config.PAD_IDX, config.UNK_IDX, config.BOS_IDX, config.EOS_IDX = word_to_id[config.PAD], word_to_id[config.UNK], word_to_id[config.BOS], word_to_id[config.EOS]\n",
    "# config.vocab = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "from model import StrSumModel\n",
    "\n",
    "model = StrSumModel(config)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
       "       [-0.201 ,  0.3212, -0.027 , ...,  0.1667, -0.0982, -0.0186],\n",
       "       ...,\n",
       "       [-1.3045,  0.3266,  0.5752, ...,  0.5891, -0.035 , -0.6161],\n",
       "       [ 0.0143,  0.353 , -0.5258, ...,  0.5506, -0.2468,  0.3779],\n",
       "       [ 0.1307,  0.0051, -0.2055, ..., -0.11  , -0.2712,  0.3053]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'sess' in globals(): sess.close()\n",
    "sess = tf.Session()\n",
    "gvi = tf.global_variables_initializer()\n",
    "sess.run(gvi)\n",
    "sess.run(model.embeddings.assign(embedding_matrix.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt_from_idx(idxs, model, vocab):\n",
    "    return [' '.join([vocab[idx] for idx in idxs if (idx != model.config.EOS_IDX and idx != model.config.PAD_IDX)])]\n",
    "\n",
    "def get_txt_from_tokens(tokens):\n",
    "    return [' '.join([token for token in l]) for l in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge(o_tokens, r_tokens, mode):\n",
    "    if o_tokens == '': return (0.0, 0.0, 0.0)\n",
    "    rouge = rouge_l_sentence_level(o_tokens, r_tokens) if mode == 'l' else rouge_n(o_tokens, r_tokens, mode)\n",
    "    return rouge[0]\n",
    "\n",
    "def get_rouges(sess, model, batch, vocab, modes=[1, 2, 'l']):\n",
    "    feed_dict = model.get_feed_dict(batch, mode='test')\n",
    "    _output_token_idxs = sess.run(model.beam_output_token_idxs, feed_dict = feed_dict)\n",
    "    rouges = []\n",
    "    for r_d, o_d in zip(batch, _output_token_idxs):\n",
    "        o_idxs = o_d[0] if len(o_d.shape) == 2 else o_d\n",
    "        o_tokens = get_txt_from_idx(o_idxs, model, vocab)\n",
    "        r_tokens = get_txt_from_tokens([r_d.summary_tokens])\n",
    "        rouge_batch = tuple([get_rouge(o_tokens, r_tokens, mode) for mode in modes])\n",
    "        rouges.append(rouge_batch)\n",
    "    return rouges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sess, batches, model, vocab):\n",
    "    losses, rouges = [], []\n",
    "    for ct, batch in batches:\n",
    "        feed_dict = model.get_feed_dict(batch, mode='test')\n",
    "        loss_batch = sess.run(model.loss, feed_dict = feed_dict)\n",
    "        rouge_batch = get_rouges(sess, model, batch, vocab)\n",
    "        losses += [loss_batch]\n",
    "        rouges += rouge_batch\n",
    "        \n",
    "    loss_mean = np.mean(losses)\n",
    "    rouge_mean = tuple(np.mean(rouges, 0))\n",
    "    return loss_mean, rouge_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "losses_train = []\n",
    "loss_log = []\n",
    "rouge_log = []\n",
    "rouge_l_max = 0\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=20)\n",
    "if len(loss_log) == 0:\n",
    "    import subprocess\n",
    "    \n",
    "    cmd_rm = 'rm -r %s' % config.modeldir\n",
    "    res = subprocess.call(cmd_rm.split())\n",
    "\n",
    "    cmd_mk = 'mkdir %s' % config.modeldir\n",
    "    res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "for ct, batch in train_batches:\n",
    "    feed_dict = model.get_feed_dict(batch)\n",
    "    _, loss_train = sess.run([model.opt, model.loss], feed_dict = feed_dict)\n",
    "    losses_train += [loss_train]\n",
    "    if ct%config.log_period==0:\n",
    "        loss_train = np.mean(losses_train)\n",
    "        loss_dev, rouge_dev = evaluate(sess, dev_batches, model, vocab)\n",
    "        rouge_l = rouge_dev[-1]\n",
    "\n",
    "        if rouge_l > rouge_l_max:\n",
    "            rouge_l_max = rouge_l\n",
    "            loss_test, rouge_test = evaluate(sess, test_batches, model, vocab)\n",
    "            saver.save(sess, config.modelpath, global_step=ct)\n",
    "\n",
    "        loss_log += [(ct, loss_train, loss_dev, loss_test)]\n",
    "        rouge_log += [rouge_dev + rouge_test]\n",
    "        losses_train = []\n",
    "\n",
    "        clear_output()\n",
    "        for i in range(len(loss_log)): \n",
    "            print 'Step: %i | LOSS TRAIN: %.3f, DEV: %.3f, TEST: %.3f ' %  loss_log[i], \n",
    "            print '| DEV ROUGE-1: %.3f, -2: %.3f, -L: %.3f | TEST ROUGE: -1: %.3f, -2: %.3f, -L: %.3f' % rouge_log[i]\n",
    "#         print_sample(sess, sample_batch, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2",
   "language": "python",
   "name": "py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
