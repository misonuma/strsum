{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "import cPickle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import load_data\n",
    "from model import StrSumModel\n",
    "from run import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(tf.flags.FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cli.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string('visible_gpu', '0', 'visible_gpu')\n",
    "\n",
    "dataname = 'sports.pkl'\n",
    "\n",
    "dataname = 'sports.pkl'\n",
    "flags.DEFINE_string('datapath', os.path.join('data', dataname), 'datapath')\n",
    "modeldir = 'model'\n",
    "modelname = 'sports'\n",
    "flags.DEFINE_string('modeldir', modeldir, 'modeldir')\n",
    "flags.DEFINE_string('modelpath', os.path.join(modeldir, 'sports'), 'modeldir')\n",
    "\n",
    "flags.DEFINE_bool('discourserank', True, 'discourserank')\n",
    "flags.DEFINE_float('damp', 0.9, 'damping factor of discourserank')\n",
    "\n",
    "flags.DEFINE_integer('epochs', 1000, 'epochs')\n",
    "flags.DEFINE_integer('log_period', 500, 'log_period')\n",
    "\n",
    "flags.DEFINE_string('opt', 'Adagrad', 'optimizer')\n",
    "flags.DEFINE_float('lr', 0.1, 'lr')\n",
    "flags.DEFINE_float('norm', 1e-4, 'norm')\n",
    "flags.DEFINE_float('grad_clip', 10.0, 'grad_clip')\n",
    "flags.DEFINE_float('keep_prob', 0.95, 'keep_prob')\n",
    "flags.DEFINE_float('length_penalty_weight', 0.0, 'length_penalty_weight')\n",
    "\n",
    "flags.DEFINE_integer('dim_hidden', 256, 'dim_output')\n",
    "flags.DEFINE_integer('dim_str', 128, 'dim_output')\n",
    "flags.DEFINE_integer('dim_sent', 384, 'dim_sent')\n",
    "\n",
    "flags.DEFINE_integer('beam_width', 10, 'beam_width')\n",
    "flags.DEFINE_integer('batch_size', 8, 'batch_size')\n",
    "\n",
    "flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = flags.FLAGS\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = config.visible_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import rouge_n, rouge_l_sentence_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = '<pad>' # This has a vocab id, which is used to pad the encoder input, decoder input and target sequence\n",
    "UNK = '<unk>' # This has a vocab id, which is used to represent out-of-vocabulary words\n",
    "BOS = '<p>' # This has a vocab id, which is used at the beginning of every decoder input sequence\n",
    "EOS = '</p>' # This has a vocab id, which is used at the end of untruncated target sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_examples,  train_batches, dev_batches, test_batches, embedding_matrix, vocab, word_to_id = load_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.n_embed, config.d_embed = embedding_matrix.shape\n",
    "flags.DEFINE_integer('n_embed', embedding_matrix.shape[0], 'n_embed')\n",
    "flags.DEFINE_integer('d_embed', embedding_matrix.shape[1], 'd_embed')\n",
    "# config.maximum_iterations = max([max([d._max_sent_len(None) for d in batch]) for ct, batch in dev_batches])\n",
    "maximum_iterations = max([max([d._max_sent_len(None) for d in batch]) for ct, batch in dev_batches])\n",
    "flags.DEFINE_integer('maximum_iterations', maximum_iterations, 'maximum_iterations')\n",
    "flags.DEFINE_integer('PAD_IDX', word_to_id[PAD], 'PAD_IDX')\n",
    "flags.DEFINE_integer('UNK_IDX', word_to_id[UNK], 'UNK_IDX')\n",
    "flags.DEFINE_integer('BOS_IDX', word_to_id[BOS], 'BOS_IDX')\n",
    "flags.DEFINE_integer('EOS_IDX', word_to_id[EOS], 'EOS_IDX')\n",
    "# config.PAD_IDX, config.UNK_IDX, config.BOS_IDX, config.EOS_IDX = word_to_id[config.PAD], word_to_id[config.UNK], word_to_id[config.BOS], word_to_id[config.EOS]\n",
    "# config.vocab = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "from model import StrSumModel\n",
    "\n",
    "model = StrSumModel(config)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
       "       [-0.201 ,  0.3212, -0.027 , ...,  0.1667, -0.0982, -0.0186],\n",
       "       ...,\n",
       "       [ 0.1341,  0.2113,  0.0598, ..., -0.357 , -0.3354,  0.0216],\n",
       "       [-0.1398,  0.2545,  0.0747, ..., -0.1979,  0.4504, -0.2602],\n",
       "       [-0.0969,  0.5253,  0.3182, ...,  0.1625,  0.0848, -0.0248]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'sess' in globals(): sess.close()\n",
    "sess = tf.Session()\n",
    "gvi = tf.global_variables_initializer()\n",
    "sess.run(gvi)\n",
    "sess.run(model.embeddings.assign(embedding_matrix.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt_from_idx(idxs, model, vocab):\n",
    "    return [' '.join([vocab[idx] for idx in idxs if (idx != model.config.EOS_IDX and idx != model.config.PAD_IDX)])]\n",
    "\n",
    "def get_txt_from_tokens(tokens):\n",
    "    return [' '.join([token for token in l]) for l in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge(o_tokens, r_tokens, mode):\n",
    "    if o_tokens == '': return (0.0, 0.0, 0.0)\n",
    "    rouge = rouge_l_sentence_level(o_tokens, r_tokens) if mode == 'l' else rouge_n(o_tokens, r_tokens, mode)\n",
    "    return rouge[0]\n",
    "\n",
    "def get_rouges(sess, model, batch, vocab, modes=[1, 2, 'l']):\n",
    "    feed_dict = model.get_feed_dict(batch, mode='test')\n",
    "    _output_token_idxs = sess.run(model.beam_output_token_idxs, feed_dict = feed_dict)\n",
    "    rouges = []\n",
    "    for r_d, o_d in zip(batch, _output_token_idxs):\n",
    "        o_idxs = o_d[0] if len(o_d.shape) == 2 else o_d\n",
    "        o_tokens = get_txt_from_idx(o_idxs, model, vocab)\n",
    "        r_tokens = get_txt_from_tokens([r_d.summary_tokens])\n",
    "        rouge_batch = tuple([get_rouge(o_tokens, r_tokens, mode) for mode in modes])\n",
    "        rouges.append(rouge_batch)\n",
    "    return rouges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sess, batches, model, vocab):\n",
    "    losses, rouges = [], []\n",
    "    for ct, batch in batches:\n",
    "        feed_dict = model.get_feed_dict(batch, mode='test')\n",
    "        loss_batch = sess.run(model.loss, feed_dict = feed_dict)\n",
    "        rouge_batch = get_rouges(sess, model, batch, vocab)\n",
    "        losses += [loss_batch]\n",
    "        rouges += rouge_batch\n",
    "        \n",
    "    loss_mean = np.mean(losses)\n",
    "    rouge_mean = tuple(np.mean(rouges, 0))\n",
    "    return loss_mean, rouge_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 500 | LOSS TRAIN: 6.832, DEV: 6.638, TEST: 6.657  | DEV ROUGE-1: 0.034, -2: 0.000, -L: 0.003 | TEST ROUGE: -1: 0.043, -2: 0.000, -L: 0.003\n",
      "Step: 1000 | LOSS TRAIN: 6.442, DEV: 6.203, TEST: 6.657  | DEV ROUGE-1: 0.025, -2: 0.000, -L: 0.006 | TEST ROUGE: -1: 0.043, -2: 0.000, -L: 0.003\n",
      "Step: 1500 | LOSS TRAIN: 6.150, DEV: 6.019, TEST: 6.046  | DEV ROUGE-1: 0.047, -2: 0.000, -L: 0.034 | TEST ROUGE: -1: 0.054, -2: 0.002, -L: 0.039\n",
      "Step: 2000 | LOSS TRAIN: 5.990, DEV: 5.904, TEST: 5.932  | DEV ROUGE-1: 0.053, -2: 0.001, -L: 0.040 | TEST ROUGE: -1: 0.053, -2: 0.002, -L: 0.038\n",
      "Step: 2500 | LOSS TRAIN: 5.871, DEV: 5.823, TEST: 5.865  | DEV ROUGE-1: 0.057, -2: 0.002, -L: 0.041 | TEST ROUGE: -1: 0.066, -2: 0.004, -L: 0.046\n",
      "Step: 3000 | LOSS TRAIN: 5.811, DEV: 5.750, TEST: 5.796  | DEV ROUGE-1: 0.066, -2: 0.003, -L: 0.048 | TEST ROUGE: -1: 0.063, -2: 0.003, -L: 0.045\n",
      "Step: 3500 | LOSS TRAIN: 5.750, DEV: 5.695, TEST: 5.737  | DEV ROUGE-1: 0.064, -2: 0.005, -L: 0.047 | TEST ROUGE: -1: 0.068, -2: 0.007, -L: 0.050\n",
      "Step: 4000 | LOSS TRAIN: 5.701, DEV: 5.681, TEST: 5.737  | DEV ROUGE-1: 0.054, -2: 0.002, -L: 0.043 | TEST ROUGE: -1: 0.068, -2: 0.007, -L: 0.050\n",
      "Step: 4500 | LOSS TRAIN: 5.650, DEV: 5.603, TEST: 5.737  | DEV ROUGE-1: 0.057, -2: 0.002, -L: 0.042 | TEST ROUGE: -1: 0.068, -2: 0.007, -L: 0.050\n",
      "Step: 5000 | LOSS TRAIN: 5.615, DEV: 5.569, TEST: 5.737  | DEV ROUGE-1: 0.066, -2: 0.003, -L: 0.046 | TEST ROUGE: -1: 0.068, -2: 0.007, -L: 0.050\n",
      "Step: 5500 | LOSS TRAIN: 5.585, DEV: 5.523, TEST: 5.737  | DEV ROUGE-1: 0.063, -2: 0.004, -L: 0.045 | TEST ROUGE: -1: 0.068, -2: 0.007, -L: 0.050\n",
      "Step: 6000 | LOSS TRAIN: 5.565, DEV: 5.502, TEST: 5.557  | DEV ROUGE-1: 0.073, -2: 0.005, -L: 0.050 | TEST ROUGE: -1: 0.073, -2: 0.004, -L: 0.051\n",
      "Step: 6500 | LOSS TRAIN: 5.525, DEV: 5.494, TEST: 5.557  | DEV ROUGE-1: 0.069, -2: 0.003, -L: 0.053 | TEST ROUGE: -1: 0.073, -2: 0.004, -L: 0.051\n",
      "Step: 7000 | LOSS TRAIN: 5.494, DEV: 5.454, TEST: 5.511  | DEV ROUGE-1: 0.077, -2: 0.006, -L: 0.056 | TEST ROUGE: -1: 0.075, -2: 0.004, -L: 0.055\n",
      "Step: 7500 | LOSS TRAIN: 5.479, DEV: 5.432, TEST: 5.511  | DEV ROUGE-1: 0.048, -2: 0.002, -L: 0.032 | TEST ROUGE: -1: 0.075, -2: 0.004, -L: 0.055\n",
      "Step: 8000 | LOSS TRAIN: 5.459, DEV: 5.422, TEST: 5.511  | DEV ROUGE-1: 0.074, -2: 0.004, -L: 0.053 | TEST ROUGE: -1: 0.075, -2: 0.004, -L: 0.055\n",
      "Step: 8500 | LOSS TRAIN: 5.435, DEV: 5.400, TEST: 5.511  | DEV ROUGE-1: 0.052, -2: 0.004, -L: 0.036 | TEST ROUGE: -1: 0.075, -2: 0.004, -L: 0.055\n",
      "Step: 9000 | LOSS TRAIN: 5.406, DEV: 5.366, TEST: 5.511  | DEV ROUGE-1: 0.049, -2: 0.002, -L: 0.032 | TEST ROUGE: -1: 0.075, -2: 0.004, -L: 0.055\n",
      "Step: 9500 | LOSS TRAIN: 5.403, DEV: 5.352, TEST: 5.511  | DEV ROUGE-1: 0.039, -2: 0.003, -L: 0.027 | TEST ROUGE: -1: 0.075, -2: 0.004, -L: 0.055\n",
      "Step: 10000 | LOSS TRAIN: 5.380, DEV: 5.339, TEST: 5.511  | DEV ROUGE-1: 0.053, -2: 0.005, -L: 0.037 | TEST ROUGE: -1: 0.075, -2: 0.004, -L: 0.055\n",
      "Step: 10500 | LOSS TRAIN: 5.371, DEV: 5.318, TEST: 5.511  | DEV ROUGE-1: 0.046, -2: 0.004, -L: 0.032 | TEST ROUGE: -1: 0.075, -2: 0.004, -L: 0.055\n",
      "Step: 11000 | LOSS TRAIN: 5.361, DEV: 5.299, TEST: 5.511  | DEV ROUGE-1: 0.056, -2: 0.004, -L: 0.040 | TEST ROUGE: -1: 0.075, -2: 0.004, -L: 0.055\n",
      "Step: 11500 | LOSS TRAIN: 5.334, DEV: 5.307, TEST: 5.366  | DEV ROUGE-1: 0.058, -2: 0.009, -L: 0.043 | TEST ROUGE: -1: 0.065, -2: 0.008, -L: 0.050\n",
      "Step: 12000 | LOSS TRAIN: 5.314, DEV: 5.270, TEST: 5.337  | DEV ROUGE-1: 0.075, -2: 0.009, -L: 0.055 | TEST ROUGE: -1: 0.075, -2: 0.006, -L: 0.053\n",
      "Step: 12500 | LOSS TRAIN: 5.315, DEV: 5.263, TEST: 5.337  | DEV ROUGE-1: 0.062, -2: 0.007, -L: 0.043 | TEST ROUGE: -1: 0.075, -2: 0.006, -L: 0.053\n",
      "Step: 13000 | LOSS TRAIN: 5.294, DEV: 5.257, TEST: 5.337  | DEV ROUGE-1: 0.053, -2: 0.007, -L: 0.039 | TEST ROUGE: -1: 0.075, -2: 0.006, -L: 0.053\n",
      "Step: 13500 | LOSS TRAIN: 5.276, DEV: 5.241, TEST: 5.337  | DEV ROUGE-1: 0.057, -2: 0.005, -L: 0.038 | TEST ROUGE: -1: 0.075, -2: 0.006, -L: 0.053\n",
      "Step: 14000 | LOSS TRAIN: 5.274, DEV: 5.245, TEST: 5.337  | DEV ROUGE-1: 0.067, -2: 0.007, -L: 0.051 | TEST ROUGE: -1: 0.075, -2: 0.006, -L: 0.053\n",
      "Step: 14500 | LOSS TRAIN: 5.256, DEV: 5.226, TEST: 5.337  | DEV ROUGE-1: 0.050, -2: 0.005, -L: 0.036 | TEST ROUGE: -1: 0.075, -2: 0.006, -L: 0.053\n"
     ]
    }
   ],
   "source": [
    "losses_train = []\n",
    "loss_log = []\n",
    "rouge_log = []\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=20)\n",
    "if len(loss_log) == 0:\n",
    "    import subprocess\n",
    "    \n",
    "    cmd_rm = 'rm -r %s' % config.modeldir\n",
    "    res = subprocess.call(cmd_rm.split())\n",
    "\n",
    "    cmd_mk = 'mkdir %s' % config.modeldir\n",
    "    res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "for ct, batch in train_batches:\n",
    "    feed_dict = model.get_feed_dict(batch)\n",
    "    _, loss_train = sess.run([model.opt, model.loss], feed_dict = feed_dict)\n",
    "    losses_train += [loss_train]\n",
    "    if ct%config.log_period==0:\n",
    "        loss_train = np.mean(losses_train)\n",
    "        loss_dev, rouge_dev = evaluate(sess, dev_batches, model, vocab)\n",
    "\n",
    "        if len(rouge_log) == 0:\n",
    "            do_test = True\n",
    "        else:\n",
    "            norm = np.mean(np.array(zip(*rouge_log))[:3], 1)\n",
    "            if 0.0 in norm: norm = np.array([1, 1, 1], dtype=np.float32)\n",
    "            rouge_judge = np.sum(np.array(rouge_dev)/norm)\n",
    "            rouge_max = np.max(np.sum(np.array(zip(*rouge_log))[:3]/norm[:, np.newaxis], 0))\n",
    "            do_test = (rouge_max <= rouge_judge)\n",
    "\n",
    "        if do_test:\n",
    "            loss_test, rouge_test = evaluate(sess, test_batches, model, vocab)\n",
    "            saver.save(sess, config.modelpath, global_step=ct)\n",
    "        else:\n",
    "            loss_test = zip(*loss_log)[3][-1]\n",
    "            rouge_test = tuple(np.array(zip(*rouge_log))[3:, -1])\n",
    "\n",
    "        loss_log += [(ct, loss_train, loss_dev, loss_test)]\n",
    "        rouge_log += [rouge_dev + rouge_test]\n",
    "        losses_train = []\n",
    "\n",
    "        clear_output()\n",
    "        for i in range(len(loss_log)): \n",
    "            print 'Step: %i | LOSS TRAIN: %.3f, DEV: %.3f, TEST: %.3f ' %  loss_log[i], \n",
    "            print '| DEV ROUGE-1: %.3f, -2: %.3f, -L: %.3f | TEST ROUGE: -1: %.3f, -2: %.3f, -L: %.3f' % rouge_log[i]\n",
    "#         print_sample(sess, sample_batch, model)\n",
    "\n",
    "def print_log(sess, model, sample_batch, loss_log, rouge_log):\n",
    "    for i in range(len(loss_log)): \n",
    "        print 'Step: %i | LOSS TRAIN: %.3f, DEV: %.3f, TEST: %.3f ' %  loss_log[i], \n",
    "        print '| DEV ROUGE-1: %.3f, -2: %.3f, -L: %.3f | TEST ROUGE: -1: %.3f, -2: %.3f, -L: %.3f' % rouge_log[i]\n",
    "    print_sample(sess, sample_batch, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2",
   "language": "python",
   "name": "py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
